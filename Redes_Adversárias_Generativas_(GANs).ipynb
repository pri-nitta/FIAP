{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLoatek3+svvZCcjmo+tcw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pri-nitta/FIAP_IA/blob/main/Redes_Advers%C3%A1rias_Generativas_(GANs).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BZgk5BL3K7Kl",
        "outputId": "184f7b90-fc41-4f1e-dbcb-3610536deec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.17.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob #gerar gif\n",
        "import imageio #gerar gif\n",
        "import matplotlib.pyplot as plt # gerar gráficos\n",
        "import numpy as np # trabalhar com arrays\n",
        "import PIL # manipular imagens\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "WImAPfelQauf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (_,_) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe6YaZWgQliH",
        "outputId": "d620c7b8-9a0b-4b3a-a34e-93ab40c9dd59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') # definindo o tamanho da imagem (28x28) com 1 canal de cinza / astype para ocupar menos espaço na memória\n",
        "train_images = (train_images - 127.5) / 127.5 # normalizando a imagem para -1, 1"
      ],
      "metadata": {
        "id": "B6t1IaEVQqnq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 60000 # tamanho do conjunto de dados, volume de processamento das imagens\n",
        "BATCH_SIZE = 256 # quantidade de pixels que varia, numero de pixels aceitos"
      ],
      "metadata": {
        "id": "i1VaC8JkQuIi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE) #conjunto de dados + batch para normalizar os pixels"
      ],
      "metadata": {
        "id": "7P8rlZrpQxsW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) # entrada de um ruído randomico (a primeira imagem vai ter a profundidade 256 de 7*7)\n",
        "  model.add(layers.BatchNormalization()) # técnica que normaliza (z-score) os pesos de uma camada para a próxima camada # limita os valores em um máximo e um mínimo (ajuda a ficar com um valor estável)\n",
        "  model.add(layers.LeakyReLU())          # função de ativação onde os valores negativos sejam transmitidos (atribui um valor pequeno para aproximar o valor à 0), considera os valores negativos\n",
        "\n",
        "  model.add(layers.Reshape((7,7,256))) #para deixar no formato de imagem\n",
        "  assert model.output_shape == (None, 7, 7, 256) # None é o batch size\n",
        "\n",
        "  #Conv2DTranspose: camada de convolução para aumentar a imagem #padding aplicar bordas de zeros para ajudar a aumentar a imagem\n",
        "  model.add(layers.Conv2DTranspose(128,(5, 5), strides=(1,1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64,(5, 5), strides=(2,2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1,(5, 5), strides=(2,2), padding='same', use_bias=False, activation='tanh')) #imagem final da imagem gerada canal 1\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "rcJGk4luQ08s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100]) #ruído aleatório\n",
        "generator_image = generator(noise, training=False) # entrada inicial\n",
        "\n",
        "plt.imshow(generator_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "BpsobB-MSSui",
        "outputId": "6900418f-bcb8-4221-eed9-5742993557b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9118825330>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2,2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model\n",
        "\n",
        "  #comparar com imagens reais"
      ],
      "metadata": {
        "id": "70WUdh_WTRJK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generator_image) # valor positivo, imagem real. Valor negativo, imagem fake.\n",
        "print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7CHZLFVTcoh",
        "outputId": "3926668b-59af-477f-f515-725b335fd898"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[3.3361983e-05]], shape=(1, 1), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# configurando a função de custo (loss function)\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False) # crio uma função loss (para 0 e 1, mais prox de 1 é real)"
      ],
      "metadata": {
        "id": "gOqKCff7Tt0K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output) # dado real # 1 verdadeiro\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # dado fake # 0 falso\n",
        "  total_loss = real_loss + fake_loss # faz a comparação\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "F8ZJWwaCT4j0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# avaliar fake gerado\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output ), fake_output) # dado fake apenas"
      ],
      "metadata": {
        "id": "PjLBVlgFT8m-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definindo o otimizador da função de custo Adam\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "ED26wjmdUZzH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# para salvar o modelo\n",
        "checkpoint_dir = './training_checkpoints' #diretório para salvar pontos específicos de rede\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                               discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)"
      ],
      "metadata": {
        "id": "Bc6CqutnUcC8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 35\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "9qN1UWE_UiIv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    # Gerando ruído aleatório para a entrada do gerador\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    # Usando GradientTape para registrar as operações para o cálculo do gradiente\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Gerando imagens usando o gerador\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # Calculando as saídas reais e falsas usando o discriminador\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # Calculando as perdas do gerador e do discriminador\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Calculando os gradientes em relação aos parâmetros do gerador e do discriminador\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Aplicando os gradientes usando otimizadores separados para gerador e discriminador\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "aijXteGUUlrY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  # Itera sobre o número especificado de épocas\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()  # Marca o início do tempo para esta época\n",
        "\n",
        "    # Itera sobre os lotes de imagens no conjunto de dados\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)  # Chama a função de treinamento definida anteriormente para um lote de imagens\n",
        "\n",
        "    # Produz imagens para o GIF enquanto treina\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "    # Salva o modelo a cada 15 épocas\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    # Imprime o tempo decorrido para a época atual\n",
        "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Gera e salva imagens após a última época\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)"
      ],
      "metadata": {
        "id": "DLNz0HiHUpE6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar e salvar imagens usando o modelo treinado\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Observação: `training` é definido como False.\n",
        "  # Isso é para que todas as camadas funcionem no modo de inferência (batchnorm).\n",
        "  predictions = model(test_input, training=False)  # Modo de treinamento False para o gerador criar as imagens\n",
        "\n",
        "  # Configuração da figura para exibir as imagens geradas\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  # Itera sobre as previsões geradas\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      # Ajusta a escala e exibe a imagem gerada\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')  # Desliga as coordenadas do eixo\n",
        "\n",
        "  # Salva a imagem gerada\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()  # Exibe a imagem gerada no momento"
      ],
      "metadata": {
        "id": "hCgI9sWcUsR9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "OcZ4iiesVDvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5hanbC2VPI3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}